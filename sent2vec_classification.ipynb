{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30014f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pororo import Pororo\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87d57358",
   "metadata": {},
   "outputs": [],
   "source": [
    "se = Pororo(task=\"sentence_embedding\", lang=\"ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1633ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '../../data/step1_train.json' \n",
    "validation_file = '../../data/step1_valid.json'\n",
    "model_name_or_path = '../../data/models/electra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb91564",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_file, 'r', encoding = 'UTF-8') as fp:\n",
    "    train_data = json.load(fp)\n",
    "with open(validation_file, 'r', encoding = 'UTF-8') as fp:\n",
    "    test_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3ef715",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_lst= []\n",
    "cat_lst = []\n",
    "cont_lst = []\n",
    "for i in range(len(train_data['input_data'])):\n",
    "    label_lst.append(train_data['input_data'][i]['label'])\n",
    "    cat_lst.append(train_data['input_data'][i]['category'])\n",
    "    cont_lst.append(train_data['input_data'][i]['content']) \n",
    "    \n",
    "for i in range(len(test_data['input_data'])):\n",
    "    label_lst.append(test_data['input_data'][i]['label'])\n",
    "    cat_lst.append(test_data['input_data'][i]['category'])\n",
    "    cont_lst.append(test_data['input_data'][i]['content']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd07f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_proc_lst = []\n",
    "for i in cont_lst:\n",
    "    cont_proc_lst.append(se(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87e229da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "label = le.fit_transform(cat_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a81327c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = le.classes_\n",
    "values = le.transform(le.classes_)\n",
    "dictionary = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad6e77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IT/과학': 0,\n",
       " '경제': 1,\n",
       " '대북정책 폄훼': 2,\n",
       " '대중의 관심 유도': 3,\n",
       " '로열패밀리 신변이상': 4,\n",
       " '사설': 5,\n",
       " '사회': 6,\n",
       " '생활/문화': 7,\n",
       " '정치': 8,\n",
       " '최고지도자 신변이상': 9,\n",
       " '최고지도자 측근(당·정·군 관료) 숙청': 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cc0d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cont_proc_lst, label, test_size = 0.2,stratify = label,shuffle=True, random_state=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af04e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA gives the best result\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train, y_train)\n",
    "ypred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36926d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[  1   0   0   0   0   0   1   0   1   0   0]\n",
      " [  0  17   0   0   0   0   4   2   5   0   1]\n",
      " [  0   0   6   0   0   0   4   0   2   0   1]\n",
      " [  0   0   0  23   0   0   3   0   5   1   0]\n",
      " [  0   0   0   1  37   0   1   0   0   3   0]\n",
      " [  0   2   0   0   0   0   1   0   0   0   0]\n",
      " [  0   9   2   4   0   0 127   6  31   2   1]\n",
      " [  0   0   0   0   0   0   4  12   2   0   1]\n",
      " [  0   7   0   2   0   0  26   2 106   1   2]\n",
      " [  0   0   0   2   0   0   6   0   3  75   1]\n",
      " [  0   0   1   1   0   0   1   1   6   0  62]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.49      0.59      0.53        29\n",
      "           2       0.67      0.46      0.55        13\n",
      "           3       0.70      0.72      0.71        32\n",
      "           4       1.00      0.88      0.94        42\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.71      0.70      0.71       182\n",
      "           7       0.52      0.63      0.57        19\n",
      "           8       0.66      0.73      0.69       146\n",
      "           9       0.91      0.86      0.89        87\n",
      "          10       0.90      0.86      0.88        72\n",
      "\n",
      "    accuracy                           0.74       628\n",
      "   macro avg       0.69      0.61      0.63       628\n",
      "weighted avg       0.75      0.74      0.74       628\n",
      "\n",
      "Accuracy: 0.7420382165605095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "result = confusion_matrix(y_test, ypred)\n",
    "print('Confusion Matrix: ')\n",
    "print(result)\n",
    "result1 = classification_report(y_test, ypred)\n",
    "print('Classification Report: ')\n",
    "print (result1)\n",
    "result2 = accuracy_score(y_test,ypred)\n",
    "print(f'Accuracy: {result2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cf78435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">SVM 0.733 (0.009)\n",
      ">KNN 0.714 (0.014)\n",
      ">RF 0.669 (0.029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">ET 0.672 (0.028)\n"
     ]
    }
   ],
   "source": [
    "# spot check machine learning algorithms on the glass identification dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import KFold\n",
    "def get_models():\n",
    "    models, names = list(), list()\n",
    "    # SVM\n",
    "    models.append(LinearSVC())\n",
    "    names.append('SVM')\n",
    "    # KNN\n",
    "    models.append(KNeighborsClassifier())\n",
    "    names.append('KNN')\n",
    "\n",
    "    # RF\n",
    "    models.append(RandomForestClassifier(n_estimators=1000))\n",
    "    names.append('RF')\n",
    "    # ET\n",
    "    models.append(ExtraTreesClassifier(n_estimators=1000))\n",
    "    names.append('ET')\n",
    "\n",
    "    return models, names\n",
    "def evaluate_model(X, y, model):\n",
    "    # define evaluation procedure\n",
    "    #cv = KFold(n_splits=5, shuffle=True)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=5, n_jobs = 2)\n",
    "    return scores\n",
    "\n",
    "# define models\n",
    "models, names = get_models()\n",
    "results = list()\n",
    "# evaluate each model\n",
    "for i in range(len(models)):\n",
    "    # evaluate the model and store results\n",
    "    scores = evaluate_model(cont_proc_lst, label, models[i])\n",
    "    results.append(scores)\n",
    "    # summarize performance\n",
    "    print('>%s %.3f (%.3f)' % (names[i], mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b8289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
